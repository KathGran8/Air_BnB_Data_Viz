{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCLAIMER: WE STRONGLY RECOMMEND NOT RUNNING THE CODE SINCE SOME BLOCKS TAKE HOURS TO COMPLETE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "In this file we provide instructions on how to navigate through this folder and the correct order to inspect the code in it. \n",
    "\n",
    "Due to the large extension that a single notebook would have, code is split in several. Below is a brief expanation of what has been done in each of them.\n",
    "\n",
    "- [1_Get_data.ipynb](_1_Get_data.ipynb)<br>\n",
    "    Donwnloading all the datasets that will be used: one main Airbnb dataset and three additional datasets (for trees, rats, and touristic places) with some extra information.<br><br>\n",
    "\n",
    "- [2_Clean_data.ipynb](_2_Clean_data.ipynb)<br>\n",
    "    Prepping Airbnb dataset for analysis. This includes removal of outliers, discard of unnecessary data (columns in the dataframe) and encoding of categorical features. The output is a clean dataset stored in [data_air/AB_data_clean.csv](data_air/AB_data_clean.csv)<br><br>\n",
    "\n",
    "- [3_Clean_data_2.ipynb](_3_Clean_data_2.ipynb)<br>\n",
    "    Similar to the one above, prepping additional datasets for analysis. Only the features related to the location are kept. The output is three clean datasets, stored in [data_trees/trees_data_clean.csv](data_trees/trees_data_clean.csv), [data_rats/trees_data_clean.csv](data_rats/trees_data_clean.csv) and [data_places/trees_data_clean.csv](data_places/trees_data_clean.csv).<br><br>\n",
    "\n",
    "- [4_Merge_data.ipynb](_4_Merge_data.ipynb)<br>\n",
    "    The number of trees, rats and tourist places in 500, 1000 and 2500m are counted for each Airbnb listing in the main dataset. As a result, 3 datasets with the same length as the main one are generated. They are stored in [data_trees/trees_distances_simple.csv](data_trees/trees_distances_simple.csv), [data_rats/rats_distances_simple.csv](data_rats/rats_distances_simple.csv) and [and data_places/places_distances_simple.csv](and data_places/places_distances_simple.csv)  and merged into the main dataset afterwards, thus generating an output dataset stored in [joined_data.csv](joined_data.csv).<br><br>\n",
    "\n",
    "- [5_Data_exploration.ipynb](_5_Data_exploration.ipynb)<br>\n",
    "    We dive into our clean, now enchanced ([joined_data.csv](joined_data.csv)) Airbnb dataset and try to find a relationship between the listings' rental price and other variables in the dataset by making plots of them.<br><br>\n",
    "\n",
    "- [6_ML.ipynb](_6_ML.ipynb)<br>\n",
    "    Several machine learning models are built from the cleaned original dataset ([data_air/AB_data_clean.csv](data_air/AB_data_clean.csv)). In order to do this, a baseline test and some data prepping is done, which in some cases  involves a search of the optimal features to be fed to the models is also done.<br><br>\n",
    "\n",
    "- [7_ML_on_joined.ipynb](_7_ML_on_joined.ipynb)<br>\n",
    "    Similarly to what was done in [_6_ML.ipynb](_6_ML.ipynb), the same process followed, this time on the enhanced clean dataset with the new additional features ([joined_data.csv](joined_data.csv)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainer: Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Motivation\n",
    "#### What is your dataset?\n",
    "\n",
    "Our main dataset stores information about the Airbnb activity in New York in 2019. Its initial size is contains approximately 50,000 Airbnb listings with plenty of information about each of them such as the host name, the place location and its room type and number of reveiws, etc.\n",
    "\n",
    "The additional information is comprised in three datasets:\n",
    "- [Tree Census in New York City](https://www.kaggle.com/nycparks/tree-census)<br>\n",
    "    This dataset stores a record for every publicly owned tree in New York City and includes each of the  tree's location by borough and latitude/longitude, species, size, health, and more. Three census from 2015, 2005, and 1995 were conducted by NYC Parks and Recreation staff, TreesCount! program staff, and hundreds of volunteers. We chose the one from 2015, with almost 700,000 entries, since it is the closest in time to the records of our main Airbnb dataset.<br><br>\n",
    "\n",
    "- [NYC Rat Sightings](https://www.kaggle.com/new-york-city/nyc-rat-sightings)<br>\n",
    "    This dataset contains information about the rat sightings in New York. Data is from 2010-Sept 16th, 2017 and includes date, location (lat/lon), type of structure, borough, and community board. We filtered the dataset and chose only the reports from 2017, narrowing it down to approximately 15,000 rat sightings.<br><br>\n",
    "    \n",
    "- [348 New York Tourist Locations](https://www.kaggle.com/anirudhmunnangi/348-new-york-tourist-locations)<br>\n",
    "    This dataset gathers information about 348 tourist places in New York. It only has the name, addres and zipcode of the place, but we will figure out a way of translating this into latitude and longitude coordinates to perform our analysis.<br><br>\n",
    "\n",
    "#### Why did you choose this/these particular dataset(s)?\n",
    "#### What was your goal for the end user's experience?\n",
    "#### What is the idea?\n",
    "#### Why is it interesting?\n",
    "\n",
    "## 2. Basic stats. Let's understand the dataset better\n",
    "#### Write about your choices in data cleaning and preprocessing\n",
    "#### Write a short section that discusses the dataset stats, containing key points/plots from your exploratory data analysis.\n",
    " \n",
    "## 3. Data Analysis\n",
    "### Describe your data analysis and explain what you've learned about the dataset.\n",
    "### If relevant, talk about your machine-learning.\n",
    " \n",
    "## 4.Genre. Which genre of data story did you use?\n",
    "### Which tools did you use from each of the 3 categories of Visual Narrative (Figure 7 in Segal and Heer). Why?\n",
    "### Which tools did you use from each of the 3 categories of Narrative Structure (Figure 7 in Segal and Heer). Why?\n",
    " \n",
    " \n",
    "## 5. Visualizations.\n",
    "#### Explain the visualizations you've chosen.\n",
    "#### Why are they right for the story you want to tell?\n",
    " \n",
    "## 6. Discussion. Think critically about your creation\n",
    "#### What went well?,\n",
    "#### What is still missing? What could be improved?, Why?\n",
    " \n",
    "## 7. Contributions. Who did what?\n",
    "#### You should write (just briefly) which group member was the main responsible for which elements of the assignment. (I want you guys to understand every part of the assignment, but usually there is someone who took lead role on certain portions of the work. That's what you should explain). It is not OK simply to write \"All group members contributed equally\".\n",
    " \n",
    "## 8. Make sure that you use references when they're needed and follow academic standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
